{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Building a Rule-based Sentiment Classifier**\n",
    "This notebook is an attempt to build a rule-based sentiment classifier. It will take in a text X and return a label of \"1\" if the sentiment of the text is positive, \"-1\" if the sentiment of the text is negative, and \"0\" if the sentiment of the text is neutral. You can test the accuracy of your classifier on the Stanford Sentiment Treebank by running the notebook all the way to end.\n",
    "\n",
    "The final way the classifier decides whether to assign a positive, negative, or neutral label is by calculating the dot product feature_weights * extract_features(X), and if the value is greater than zero, return 1, less than zero return -1, and if exactly zero return 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(x: str) -> dict[str, float]:\n",
    "    features = {}\n",
    "    x_split = x.split(' ')\n",
    "    \n",
    "    good_words = ['love', 'good', 'nice', 'great', 'enjoy', 'enjoyed']\n",
    "    bad_words = ['hate', 'bad', 'terrible', 'disappointing', 'sad', 'lost', 'angry']\n",
    "    \n",
    "    for x_words in x_split:\n",
    "        if x_words in good_words:\n",
    "            features['good_word_count'] = features.get('good_word_count', 0) + 1\n",
    "        if x_words in bad_words:\n",
    "            features['bad_word_count'] = features.get('bad_word_count', 0) + 1 \n",
    "            \n",
    "    features['bias'] = 1\n",
    "    \n",
    "    return features\n",
    "    \n",
    "feature_weights = {'good_word_count':1.0,'bad_word_count': -1.0, 'bias':0.5 }\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'good_word_count': 2, 'bad_word_count': 1, 'bias': 1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features(\"I love to play football because it is nice and sad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">From the example above, we can see that the function successfully extracts the number of good and bad words in the input (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reading the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal .\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def read_xy_data(filename: str) -> tuple[list[str], list[int]]:\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            label, text = line.strip().split(' ||| ')\n",
    "            x_data.append(text)\n",
    "            y_data.append(int(label))\n",
    "    return x_data, y_data\n",
    "\n",
    "x_train, y_train = read_xy_data('./data/train.txt')\n",
    "x_test, y_test = read_xy_data('./data/test.txt') \n",
    "\n",
    "print(x_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Run the Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifier(x: str) -> int:\n",
    "    score = 0\n",
    "\n",
    "    for feat_name, feat_value in extract_features(x).items():\n",
    "        score = score + feat_value * feature_weights.get(feat_name, 0)\n",
    "        \n",
    "    if score > 1:\n",
    "        return 1\n",
    "    elif score < -1:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_classifier(\"I hate to play football because it is nice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Calculate Accuracy**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(x_data: list[str], y_data: list[int]) -> float:\n",
    "    total_number = 0\n",
    "    correct_number = 0\n",
    "    for x, y in zip(x_data, y_data, strict=True):\n",
    "        y_pred = run_classifier(x)\n",
    "        total_number += 1\n",
    "        if y == y_pred:\n",
    "            correct_number += 1\n",
    "    return correct_number / float(total_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 389, 1: 909, -1: 912}\n"
     ]
    }
   ],
   "source": [
    "label_count = {}\n",
    "for y in y_test:\n",
    "    if y not in label_count:\n",
    "        label_count[y] = 0\n",
    "    label_count[y] += 1\n",
    "print(label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.21594101123595505\n",
      "Dev/test accuracy: 0.19411764705882353\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calculate_accuracy(x_train, y_train)\n",
    "test_accuracy = calculate_accuracy(x_test, y_test)\n",
    "print(f'Train accuracy: {train_accuracy}')\n",
    "print(f'Dev/test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ERROR ANALYSIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def find_errors(x_data, y_data):\n",
    "    error_ids = []\n",
    "    y_preds = []\n",
    "    for i, (x, y) in enumerate(zip(x_data, y_data)):\n",
    "        y_preds.append(run_classifier(x))\n",
    "        if y != y_preds[-1]:\n",
    "            error_ids.append(i)\n",
    "    for _ in range(5):\n",
    "        my_id = random.choice(error_ids)\n",
    "        x, y, y_pred = x_data[my_id], y_data[my_id], y_preds[my_id]\n",
    "        print(f'{x}\\ntrue label: {y}\\npredicted label: {y_pred}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard-core slasher aficionados will find things to like ... but overall the Halloween series has lost its edge .\n",
      "true label: -1\n",
      "predicted label: 0\n",
      "\n",
      "A thoroughly awful movie -- dumb , narratively chaotic , visually sloppy ... a weird amalgam of ` The Thing ' and a geriatric ` Scream . '\n",
      "true label: -1\n",
      "predicted label: 0\n",
      "\n",
      "This toothless Dog , already on cable , loses all bite on the big screen .\n",
      "true label: -1\n",
      "predicted label: 0\n",
      "\n",
      "The Cat 's Meow marks a return to form for director Peter Bogdanovich ...\n",
      "true label: 1\n",
      "predicted label: 0\n",
      "\n",
      "Off the Hook is overlong and not well-acted , but credit writer-producer-director Adam Watstein with finishing it at all .\n",
      "true label: -1\n",
      "predicted label: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_errors(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
